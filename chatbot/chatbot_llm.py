import os
import time
from pathlib import Path
import requests
import pandas as pd
from dotenv import load_dotenv
from openai import OpenAI

# Carrega .env (na raiz do projeto)
BASE_DIR = Path(__file__).resolve().parent.parent
load_dotenv(BASE_DIR / ".env")

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))


class ChatbotEstudanteLLM:

    def __init__(self, api_url: str = "http://localhost:8000"):
        self.api_url = api_url
        self.usuario_atual = None
        self.dados_aluno = {}
        self.perguntas_feitas = 0  # evitar ficar dando muitos "ol√°"


    # Usa GPT-4o-mini (ou outro modelo definido) para respostas inteligentes durante a conversa
    def obter_resposta_llm(self, msg_do_usuario: str, contexto: str = "") -> str:

        prompt_sistema = f"""
        Voc√™ √© o EduScore, um assistente de IA especializado em educa√ß√£o b√°sica
        e prepara√ß√£o para vestibular.

        Seu principal objetivo √© ajudar professores, coordenadores e estudantes
        a entenderem o desempenho em disciplinas do ensino m√©dio, com foco em:
        - notas previstas
        - engajamento (presen√ßa, estudo, simulados)
        - prepara√ß√£o para ENEM e vestibulares

        Contexto: {contexto}

        Regras:
        - Seja conversacional, claro e profissional.
        - Pode usar emojis de forma moderada.
        - N√£o repita cumprimentos como "Ol√°" ou "Oi" toda hora.
        - Quando fizer perguntas sobre dados, explique POR QUE essa informa√ß√£o √© importante.
        - Nunca invente n√∫meros, notas ou diagn√≥sticos cl√≠nicos.
        """

        try:
            response = client.chat.completions.create(
                model=os.getenv("OPENAI_MODEL", "gpt-4o-mini"),
                messages=[
                    {"role": "system", "content": prompt_sistema},
                    {"role": "user", "content": msg_do_usuario},
                ],
                max_tokens=300,
                temperature=0.7,
            )
            return response.choices[0].message.content
        except Exception:
            return "Estou com uma instabilidade t√©cnica agora, mas podemos continuar com o fluxo padr√£o."


    def msg_boas_vindas(self):
        print("=" * 60)
        print("CHATBOT INTELIGENTE DE PREVIS√ÉO DE NOTAS & VESTIBULAR")
        print("=" * 60)

        msg = """
        Seja bem-vindo! Sou o EduScore, seu assistente inteligente.

        Vou te ajudar a analisar o desempenho de um aluno em uma disciplina
        do ensino m√©dio, prevendo nota, risco de reprova√ß√£o e n√≠vel de prepara√ß√£o
        para vestibular, usando:
        ‚Ä¢ Modelos de Machine Learning treinados com dados sint√©ticos
        ‚Ä¢ An√°lise de IA (LLM) focada na disciplina
        ‚Ä¢ Recomenda√ß√µes espec√≠ficas para professor e estudante

        Primeiro, vou entender quem est√° usando o sistema.
        """

        response = self.obter_resposta_llm(msg)
        print(f"\n: {response}")

    #Autentica√ß√£o simples de usu√°rio a partir de um CSV
    def autenticar_usuario(self):

        try:
            usuario_path = BASE_DIR / "modelo_ml" / "data" / "dados_usuarios.csv"
            usuarios_df = pd.read_csv(usuario_path)

            print("\nUsu√°rios dispon√≠veis:")
            for _, user in usuarios_df.iterrows():
                print(f"  {user['usuario_id']}. {user['nome']} ({user['cargo']})")

            while True:
                try:
                    usuario_id = int(input("\nDigite seu ID de usu√°rio: "))
                    user = usuarios_df[usuarios_df["usuario_id"] == usuario_id]

                    if not user.empty:
                        self.usuario_atual = user.iloc[0].to_dict()

                        contexto = (
                            f"Usu√°rio: {self.usuario_atual['nome']}, "
                            f"{self.usuario_atual['cargo']}, "
                            f"{self.usuario_atual['experiencia_anos']} anos de experi√™ncia."
                        )
                        greeting_msg = (
                            "O usu√°rio acabou de fazer login. "
                            "Cumprimente-o e comente brevemente como a experi√™ncia dele "
                            "pode ajudar na an√°lise de alunos e disciplinas."
                        )

                        greeting = self.obter_resposta_llm(greeting_msg, contexto)
                        print(f"\n >> {greeting}")
                        return True
                    else:
                        print("‚ùå Usu√°rio n√£o encontrado. Tente novamente.")
                except ValueError:
                    print("‚ùå Digite um n√∫mero v√°lido.")
        except Exception as e:
            print(f"‚ùå Erro ao carregar usu√°rios: {e}")
            return False


    # Gera perguntas espec√≠ficas para cada campo, aproveitando LLM ou perguntas fixas
    def obter_pergunta(self, campo: str, config: dict) -> str:

        # Perguntas pr√©-definidas (evita sobrecarregar o LLM e mant√©m consist√™ncia)
        perguntas_predefinidas = {
            "serie": (
                "Em que s√©rie do ensino m√©dio o aluno est√° (1¬∫, 2¬∫ ou 3¬∫ ano)? "
                "Isso √© importante porque a cobran√ßa de conte√∫do e o foco em vestibular mudam por s√©rie."
            ),
            "disciplina": (
                "Qual disciplina voc√™ quer analisar (por exemplo, Matem√°tica, Portugu√™s, F√≠sica...)? "
                "A disciplina define quais conte√∫dos s√£o mais cr√≠ticos para avalia√ß√£o e vestibular."
            ),
            "perfil_base": (
                "Como voc√™ classificaria o perfil geral desse aluno nas mat√©rias, "
                "pensando no hist√≥rico recente? (forte, mediano ou em_risco). "
                "Isso ajuda a ajustar as expectativas e recomenda√ß√µes."
            ),
            "nota_prova1": (
                "Qual foi a nota aproximada do aluno na primeira prova dessa disciplina (0 a 10)? "
                "Ela nos d√° um primeiro term√¥metro do desempenho."
            ),
            "nota_prova2": (
                "E na segunda prova, qual foi a nota aproximada (0 a 10)? "
                "Comparar provas ajuda a ver evolu√ß√£o ou queda."
            ),
            "nota_projeto": (
                "Qual a nota aproximada em trabalhos/projetos nessa disciplina (0 a 10)? "
                "Projetos costumam medir aplica√ß√£o pr√°tica e envolvimento."
            ),
            "nota_listas": (
                "E nas listas de exerc√≠cios/atividades, que nota voc√™ atribuiria (0 a 10)? "
                "Listas mostram consist√™ncia no estudo ao longo do tempo."
            ),
            "presenca_percentual": (
                "Qual a presen√ßa aproximada do aluno nessa disciplina (%)? "
                "A presen√ßa impacta muito a aprendizagem e explica v√°rias dificuldades."
            ),
            "estudos_semanais_horas": (
                "Em m√©dia, quantas horas por semana o aluno dedica √† disciplina fora da aula? "
                "Isso ajuda a medir o esfor√ßo real de estudo."
            ),
            "acessos_plataforma": (
                "Quantos acessos √† plataforma/AVA da disciplina o aluno teve nas √∫ltimas semanas (aprox.)? "
                "Isso mostra engajamento com materiais digitais."
            ),
            "simulados_feitos": (
                "Quantos simulados relacionados √† disciplina (ENEM/vestibular) o aluno fez recentemente? "
                "Simulados s√£o fundamentais para avaliar preparo para provas externas."
            ),
            "dificuldade_disciplina": (
                "Em uma escala de 1 a 5, qual o n√≠vel de dificuldade que o aluno sente nessa disciplina "
                "(1=muito f√°cil, 5=muito dif√≠cil)? Isso ajuda a calibrar as recomenda√ß√µes."
            ),
        }

        if campo in perguntas_predefinidas:
            return perguntas_predefinidas[campo]

        # Fallback: gerar pergunta com LLM
        if self.perguntas_feitas > 0:
            prompt_de_pergunta = (
                f"Fa√ßa uma pergunta direta sobre: {config['pergunta']}. "
                "Explique brevemente por que √© importante. N√ÉO use 'Ol√°' ou 'Oi'."
            )
        else:
            prompt_de_pergunta = (
                f"Fa√ßa uma pergunta natural sobre: {config['pergunta']}. "
                "Explique brevemente por que essa informa√ß√£o √© importante."
            )

        contexto = (
            f"Coletando '{campo}' para an√°lise de desempenho escolar. "
            f"Usu√°rio: {self.usuario_atual['nome'] if self.usuario_atual else 'desconhecido'}. "
            f"Pergunta n√∫mero: {self.perguntas_feitas + 1}."
        )

        return self.obter_resposta_llm(prompt_de_pergunta, contexto)


    # Coleta dados do aluno + disciplina via conversa√ß√£o
    def coletar_dados_aluno(self):

        print("\n" + "=" * 50)
        print("COLETA DE DADOS DO ALUNO")
        print("=" * 50)

        disciplinas = [
            "Matem√°tica",
            "Portugu√™s",
            "F√≠sica",
            "Qu√≠mica",
            "Biologia",
            "Hist√≥ria",
            "Geografia",
            "Ingl√™s",
            "Reda√ß√£o",
        ]

        mapa_de_campos = {
            "serie": {"pergunta": "S√©rie do ensino m√©dio (1, 2 ou 3)?", "tipo": "int"},
            "disciplina": {
                "pergunta": "Disciplina do ensino m√©dio",
                "tipo": "escolha",
                "opcoes": disciplinas,
            },
            "perfil_base": {
                "pergunta": "Perfil global de desempenho",
                "tipo": "escolha",
                "opcoes": ["forte", "mediano", "em_risco"],
            },
            "nota_prova1": {
                "pergunta": "Nota da prova 1 (0 a 10)?",
                "tipo": "float",
            },
            "nota_prova2": {
                "pergunta": "Nota da prova 2 (0 a 10)?",
                "tipo": "float",
            },
            "nota_projeto": {
                "pergunta": "Nota de trabalhos/projetos (0 a 10)?",
                "tipo": "float",
            },
            "nota_listas": {
                "pergunta": "Nota em listas/atividades (0 a 10)?",
                "tipo": "float",
            },
            "presenca_percentual": {
                "pergunta": "Presen√ßa na disciplina (%)",
                "tipo": "float",
            },
            "estudos_semanais_horas": {
                "pergunta": "Horas de estudo por semana na disciplina",
                "tipo": "float",
            },
            "acessos_plataforma": {
                "pergunta": "Acessos √† plataforma da disciplina (√∫ltimas semanas)",
                "tipo": "int",
            },
            "simulados_feitos": {
                "pergunta": "Simulados feitos relacionados √† disciplina",
                "tipo": "int",
            },
            "dificuldade_disciplina": {
                "pergunta": "Dificuldade sentida (1 a 5)",
                "tipo": "float",
            },
        }

        self.perguntas_feitas = 0
        self.dados_aluno = {}

        for campo, config in mapa_de_campos.items():
            pergunta = self.obter_pergunta(campo, config)
            print(f"\nü§ñ: {pergunta}")
            self.perguntas_feitas += 1

            while True:
                entrada_usuario = input("üë§: ").strip()
                try:
                    if config["tipo"] == "int":
                        valor = int(entrada_usuario)
                        self.dados_aluno[campo] = valor
                        print(f">> Registrado: {valor}")
                        break
                    elif config["tipo"] == "float":
                        limpar = (
                            entrada_usuario.replace("R$", "")
                            .replace(".", "")
                            .replace(",", ".")
                        )
                        valor = float(limpar)
                        self.dados_aluno[campo] = valor
                        print(f">> Registrado: {valor}")
                        break
                    elif config["tipo"] == "escolha":
                        escolha_do_usuario = entrada_usuario.strip().lower()
                        opcoes = [opt.lower() for opt in config["opcoes"]]
                        if escolha_do_usuario in opcoes:
                            original = config["opcoes"][opcoes.index(escolha_do_usuario)]
                            self.dados_aluno[campo] = original
                            print(f">> Selecionado: {original}")
                            break
                        else:
                            print(
                                f"‚ùå Escolha uma das op√ß√µes: {', '.join(config['opcoes'])}"
                            )
                            print(
                                "Dica: voc√™ pode digitar em min√∫sculas, "
                                "eu fa√ßo o ajuste."
                            )
                    else:
                        self.dados_aluno[campo] = entrada_usuario
                        break
                except ValueError:
                    print("‚ùå Formato inv√°lido. Tente novamente.")

        # Preenche um aluno_id fake para manter compatibilidade com o modelo, se precisar
        self.dados_aluno.setdefault("aluno_id", 0)

        return True


    # Aqui √© somente para mostrar um resumo do projeto
    def exibir_resumo_aluno(self):
        print("\n" + "=" * 50)
        print("RESUMO DO CASO DO ALUNO")
        print("=" * 50)

        resumo_contexto = (
            f"Dados coletados do aluno para an√°lise de disciplina e vestibular: "
            f"{self.dados_aluno}. "
            f"Usu√°rio respons√°vel: {self.usuario_atual['nome'] if self.usuario_atual else 'Desconhecido'}."
        )

        resumo_prompt = (
            "Fa√ßa um resumo amig√°vel e conciso do caso do aluno, destacando: "
            "disciplina, s√©rie, presen√ßa, esfor√ßo de estudo e uso de simulados. "
            "N√£o repita cumprimentos como 'Ol√°'. Seja objetivo e motivador."
        )

        resumo = self.obter_resposta_llm(resumo_prompt, resumo_contexto)
        print(f"\n >> {resumo}")

        print("\n DADOS T√âCNICOS:")
        print(f"   S√©rie: {self.dados_aluno['serie']}¬∫ ano do EM")
        print(f"   Disciplina: {self.dados_aluno['disciplina']}")
        print(f"   Perfil base: {self.dados_aluno['perfil_base']}")
        print(f"   Prova 1: {self.dados_aluno['nota_prova1']}")
        print(f"   Prova 2: {self.dados_aluno['nota_prova2']}")
        print(f"   Projeto: {self.dados_aluno['nota_projeto']}")
        print(f"   Listas: {self.dados_aluno['nota_listas']}")
        print(f"   Presen√ßa: {self.dados_aluno['presenca_percentual']}%")
        print(
            f"   Estudo semanal: {self.dados_aluno['estudos_semanais_horas']} h/sem"
        )
        print(f"   Acessos AVA: {self.dados_aluno['acessos_plataforma']}")
        print(f"   Simulados: {self.dados_aluno['simulados_feitos']}")
        print(
            f"   Dificuldade sentida: {self.dados_aluno['dificuldade_disciplina']} (1 a 5)"
        )


    # √â onde √© acontece a an√°lise completa ML + LLM
    def obter_analise_ia(self):

        print("\nANALISANDO COM IA...")
        print("-" * 30)

        for i in range(3):
            print("Processando" + "." * (i + 1), end="\r")
            time.sleep(0.7)
        print("An√°lise conclu√≠da!    ")

        try:
            resp = requests.post(
                f"{self.api_url}/analisar-com-llm",
                json=self.dados_aluno,
                timeout=60,
            )

            if resp.status_code == 200:
                return resp.json()
            else:
                print(f"‚ùå Erro na API: {resp.status_code} - {resp.text}")
                return None
        except requests.exceptions.ConnectionError:
            print("‚ùå Erro: API n√£o est√° rodando.")
            print("Execute: cd api && python app.py")
            return None
        except Exception as e:
            print(f"‚ùå Erro inesperado: {e}")
            return None


    # Exibe o resultado da an√°lise ML + LLM
    def exibir_resultados(self, analise: dict):

        print("\n" + "=" * 60)
        print("RESULTADO DA AN√ÅLISE INTELIGENTE (EduScore IA)")
        print("=" * 60)

        ml_pred = analise.get("ml_predicao", {})
        analise_llm = analise.get("analise_llm", {})
        nota = ml_pred.get("nota_prevista", 0.0)
        prob_aprov = ml_pred.get("prob_aprovacao", 0.0)
        risco = ml_pred.get("risco", "desconhecido")
        vestibular_score = ml_pred.get("vestibular_score", 0.0)
        nivel_prep = ml_pred.get("nivel_preparacao", "desconhecido")

        emoji_status = "‚úÖ" if risco == "baixo" else "‚ö†Ô∏è" if risco == "moderado" else "‚ùå"

        print(f"\n{emoji_status} RISCO NA DISCIPLINA: {risco.upper()}")
        print(f"Nota prevista: {nota:.2f} / 10")
        print(f"Probabilidade de aprova√ß√£o: {prob_aprov:.1%}")
        print(f"Score de prepara√ß√£o para vestibular: {vestibular_score:.1f} / 100")
        print(f"N√≠vel de prepara√ß√£o: {nivel_prep}")

        barra = 30
        preenchimento = int(prob_aprov * barra)
        bar = "‚ñà" * preenchimento + "‚ñë" * (barra - preenchimento)
        print(f"\nProbabilidade visual: [{bar}] {prob_aprov:.1%}")

        print("\nEXPLICA√á√ÉO DO CASO:")
        print("-" * 40)
        print(analise_llm.get("explicacao", "(sem explica√ß√£o do LLM)"))

        print("\nRECOMENDA√á√ïES PARA O PROFESSOR:")
        print("-" * 40)
        print(analise_llm.get("recomendacoes_professor", "(sem recomenda√ß√µes)"))

        print("\nRECOMENDA√á√ïES PARA O ALUNO (VESTIBULAR):")
        print("-" * 40)
        print(analise_llm.get("recomendacoes_aluno", "(sem recomenda√ß√µes)"))

        print("\n" + analise.get("insights_combinados", ""))

    
    # Fluxo principal, executa o chatbot conversacional de ponta a ponta
    def run(self):

        try:
            # Verifica se API est√° de p√©
            try:
                response = requests.get(f"{self.api_url}/health", timeout=5)
                if response.status_code != 200:
                    print("‚ùå API n√£o est√° saud√°vel!")
                    print(response.text)
                    return
            except Exception:
                print("‚ùå API n√£o est√° rodando!")
                print("Execute: cd api && python app.py")
                return

            self.msg_boas_vindas()

            if not self.autenticar_usuario():
                return

            while True:
                print("\n" + "=" * 60)
                print("NOVA AN√ÅLISE DE ALUNO/DISCIPLINA")
                print("=" * 60)

                # reset do contador
                self.perguntas_feitas = 0

                if not self.coletar_dados_aluno():
                    break

                self.exibir_resumo_aluno()

                confirmar = (
                    input("\nDeseja analisar esse caso com IA? (s/n): ")
                    .strip()
                    .lower()
                )
                if confirmar == "s":
                    analises = self.obter_analise_ia()
                    if analises:
                        self.exibir_resultados(analises)
                    else:
                        print("‚ùå N√£o foi poss√≠vel realizar a an√°lise.")

                nova_analise = (
                    input("\nDeseja analisar outro aluno/disciplina? (s/n): ")
                    .strip()
                    .lower()
                )
                if nova_analise != "s":
                    break

                self.dados_aluno = {}

            # Hora da despedida
            msg_despedida = (
                "O usu√°rio est√° encerrando a sess√£o no EduScore. "
                "Fa√ßa uma despedida amig√°vel, reconhecendo o esfor√ßo em usar dados para "
                "ajudar alunos a melhorarem seu desempenho."
            )
            despedida = self.obter_resposta_llm(msg_despedida)
            print(f"\n >> {despedida}")

        except KeyboardInterrupt:
            print("\n\nSess√£o encerrada pelo usu√°rio.")
        except Exception as e:
            print(f"‚ùå Erro inesperado: {e}")


if __name__ == "__main__":
    chatbot = ChatbotEstudanteLLM()
    chatbot.run()
